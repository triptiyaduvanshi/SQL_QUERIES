Use  maven_advanced_sql;
show tables;
/1...* A group of travelers embark on world tours starting with their home cities. Each traveler 
has an undecided itinerary that evolves over the course of the tour. Some travelers decide to 
abruptly end their journey mid-travel and live in their last destination.
Given the dataset of dates on which they travelled between different pairs of cities, 
can you find out how many travellers ended back in their home city? For simplicity, 
you can assume that each traveler made at most one trip between two cities in a day.*/

describe employee_salary_data;
CREATE TABLE travel_history (date DATE, start_city VARCHAR(50), end_city VARCHAR(50), traveler VARCHAR(50));

INSERT INTO travel_history (date, start_city, end_city, traveler) VALUES ('2024-01-01', 'Delhi', 'Dubai', 'Amit'),
 ('2024-01-05', 'Dubai', 'London', 'Amit'), ('2024-01-10', 'London', 'Delhi', 'Amit'), 
 ('2024-02-01', 'Mumbai', 'Singapore', 'Priya'), ('2024-02-05', 'Singapore', 'Sydney', 'Priya'), 
 ('2024-02-10', 'Sydney', 'New York', 'Priya'), ('2024-03-01', 'Kolkata', 'Bangkok', 'Raj'), 
 ('2024-03-03', 'Bangkok', 'Tokyo', 'Raj'), ('2024-03-07', 'Tokyo', 'Kolkata', 'Raj'), 
 ('2024-04-01', 'Bangalore', 'Paris', 'Neha'), ('2024-04-05', 'Paris', 'Rome', 'Neha'),
 ('2024-04-10', 'Rome', 'Berlin', 'Neha'), ('2024-05-01', 'Chennai', 'Dubai', 'Arjun'), 
 ('2024-05-03', 'Dubai', 'Amsterdam', 'Arjun'), ('2024-05-06', 'Amsterdam', 'Chennai', 'Arjun'); 
 
 with base as (select *,row_number()over(partition by traveler order by date) ranks from travel_history),
 base2 as(select traveler, end_city as endcity from base where ranks=(select max(ranks) from base)
 group by traveler, end_city),
 base3 as (select traveler, start_city as startcity from base where ranks=(select min(ranks) from base)
 group by traveler, start_city)
 select b2.traveler, b3.startcity, b2.endcity from base2 b2 join base3 b3 on b2.traveler=b3.traveler
 where b3.startcity=b2.endcity;



/*2... Each Employee is assigned one territory and is responsible for the Customers from this territory. 
There may be multiple employees assigned to the same territory.
Write a query to get the Employees who are responsible for the maximum number of Customers.
 Output the Employee ID and the number of Customers*/

CREATE TABLE map_employee_territory (empl_id VARCHAR(10), territory_id VARCHAR(10));

INSERT INTO map_employee_territory (empl_id, territory_id) VALUES ('E849', 'T3'), 
('E850', 'T3'), ('E851', 'T3'), ('E852', 'T1'), ('E853', 'T2'), ('E854', 'T5'), 
('E855', 'T5'), ('E856', 'T4'), ('E857', 'T2');

CREATE TABLE map_customer_territory (cust_id VARCHAR(10), territory_id VARCHAR(10));

INSERT INTO map_customer_territory (cust_id, territory_id) VALUES ('C273', 'T3'), 
('C274', 'T3'), ('C275', 'T1'), ('C276', 'T1'), ('C277', 'T1'), ('C278', 'T2'), 
('C279', 'T2'), ('C280', 'T4'), ('C281', 'T4'), ('C282', 'T4'), ('C283', 'T4'), 
('C284', 'T5'), ('C285', 'T5'), ('C286', 'T3'), ('C287', 'T3');

with base as (select e.empl_id,e.territory_id,cust_id from map_employee_territory e join map_customer_territory c
on e.territory_id=c.territory_id),
base2 as (select empl_id,(count(cust_id)) as count from base group by empl_id)
select empl_id,count from base2 where count=( select max(count) from base2);


/*3... Write a query to return Territory and corresponding Sales Growth.
 Compare growth between periods Q4-2021 vs Q3-2021.
 If Territory (say T123) has Sales worth $100 in Q3-2021 and Sales worth $110 in Q4-2021,
 then the Sales Growth will be 10% [ i.e. = ((110 - 100)/100) * 100 ]*/
 
 CREATE TABLE fct_customer_sale (cust_id VARCHAR(50), 
 prod_sku_id VARCHAR(50), order_date DATETIME, 
 order_value BIGINT, order_id VARCHAR(50));

CREATE TABLE map_customer_territories (cust_id VARCHAR(50),
 territory_id VARCHAR(50));

INSERT INTO fct_customer_sale (cust_id, prod_sku_id, order_date, 
order_value, order_id) VALUES ('C001', 'P100', '2021-07-15', 100, 'O1001'),
 ('C002', 'P101', '2021-07-20', 200, 'O1002'),
 ('C001', 'P100', '2021-10-05', 150, 'O1003'), 
 ('C002', 'P101', '2021-10-10', 250, 'O1004'), 
 ('C003', 'P102', '2021-08-22', 180, 'O1005'), 
 ('C003', 'P102', '2021-11-30', 210, 'O1006');
 

INSERT INTO map_customer_territories (cust_id, territory_id) VALUES  ('C001', 'T001'),
 ('C002', 'T002'), ('C003', 'T003');
 /* one way to write it*/
with base as (select c.cust_id, c.prod_sku_id, monthname(c.order_date) as namemonth,
year(c.order_date) as nameyear,  quarter(c.order_date) AS quartername,
c.order_value, c.order_id ,t.territory_id from
fct_customer_sale c join map_customer_territories t on c.cust_id=t.cust_id),
base2 as (select territory_id,sum(order_value)as revenue,quartername,nameyear from 
base group by territory_id,nameyear,quartername),
base3 as (select territory_id,revenue,nameyear,quartername,
row_number()over(partition by territory_id order by revenue ) as ranks,
lead(revenue)over(partition by territory_id
 order by revenue ) as next
 from base2)
 select territory_id, concat(((next-revenue)/revenue)*100,'%') as sales_growth_perc 
 from base3 where next is not null;
 
 /* other way */
 with base as (select t.territory_id,  year(c.order_date) as nameyear,
 quarter(c.order_date) AS quartername,sum(c.order_value)as revenue from
fct_customer_sale c join map_customer_territories t on c.cust_id=t.cust_id
group by t.territory_id, year(c.order_date),
 quarter(c.order_date))
 select q3.territory_id, concat(((q4.revenue-q3.revenue)/q3.revenue)*100,'%') as sales_growth_perc 
 from base q3 join base q4 on q3.territory_id=q4.territory_id
 where q3.nameyear=q4.nameyear and q3.quartername=3 and q4.quartername=4
 where next is not null;

/*4... From users who had their first session as a viewer, how many streamer 
sessions have they had? Return the user id and number of sessions in descending order.
 In case there are users with the same number of sessions, order them by ascending user id.*/
 
 CREATE TABLE twitch_sessions (user_id BIGINT, session_start DATETIME, session_end DATETIME, 
 session_id BIGINT PRIMARY KEY, session_type VARCHAR(20) CHECK (session_type IN ('viewer', 'streamer')));

INSERT INTO twitch_sessions (user_id, session_start, session_end, session_id, session_type) 
VALUES (101, '2024-02-01 10:00:00', '2024-02-01 11:00:00', 1, 'viewer'), 
(101, '2024-02-02 14:00:00', '2024-02-02 15:30:00', 2, 'streamer'), 
(102, '2024-02-01 09:30:00', '2024-02-01 10:30:00', 3, 'viewer'), 
(102, '2024-02-03 16:00:00', '2024-02-03 17:00:00', 4, 'streamer'),
 (102, '2024-02-05 18:00:00', '2024-02-05 19:30:00', 5, 'streamer'), 
 (103, '2024-02-02 11:00:00', '2024-02-02 12:00:00', 6, 'viewer'), 
 (104, '2024-02-01 08:30:00', '2024-02-01 09:00:00', 7, 'viewer'), 
 (104, '2024-02-04 20:00:00', '2024-02-04 21:00:00', 8, 'streamer'),
 (104, '2024-02-06 22:00:00', '2024-02-06 23:00:00', 9, 'streamer'),
 (104, '2024-02-07 15:00:00', '2024-02-07 16:30:00', 10, 'streamer');
 /* this query gives user id which have session as viwer and streamer*/
 select  user_id,count(session_type='streamer')  from twitch_sessions t1 where t1.user_id in
 (select user_id  from twitch_sessions t2 where 
session_type ='viewer')
group by user_id;
 /* we require user_id with first session as viewer and also had streamer session*/
 with base as (select user_id, session_type,row_number()over(partition by user_id order by
 session_start) as ranks  from twitch_sessions t2),
base2 as (select  user_id  from base where ranks=1 and session_type='viewer')
select t1.user_id, count(*) from twitch_sessions t1 join base2 b on b.user_id=t1.user_id
where t1.session_type='streamer'
group by user_id order by count(*) desc;

/* other way*/
 select  user_id,count(session_type='streamer')  from twitch_sessions t1 where t1.user_id in
 (select user_id  from twitch_sessions t2 where 
session_type ='viewer')
group by user_id;
 /* we require user_id with first session as viewer and also had streamer session*/
 with base as (select user_id, min(session_start) from twitch_sessions t2 
 where session_type='viewer'
 group by user_id )
select t1.user_id, count(*) from twitch_sessions t1 join base b on b.user_id=t1.user_id
where t1.session_type='streamer'
group by user_id order by count(*) desc;


/*5... Select the most popular client_id based on a count of the number of users who have at 
least 50% of their events from the following list: 'video call received', 'video call sent',
 'voice call received', 'voice call sent'.*/
 
 CREATE TABLE fact_event (id BIGINT PRIMARY KEY, time_id DATETIME, user_id VARCHAR(50),
 customer_id VARCHAR(50), client_id VARCHAR(50), event_type VARCHAR(50), event_id BIGINT);
 
 INSERT INTO fact_event (id, time_id, user_id, customer_id, client_id, event_type, event_id)
 VALUES (1, '2024-02-01 10:00:00', 'U1', 'C1', 'CL1', 'video call received', 101),
 (2, '2024-02-01 10:05:00', 'U1', 'C1', 'CL1', 'video call sent', 102),
 (3, '2024-02-01 10:10:00', 'U1', 'C1', 'CL1', 'message sent', 103),
 (4, '2024-02-01 11:00:00', 'U2', 'C2', 'CL2', 'voice call received', 104),
 (5, '2024-02-01 11:10:00', 'U2', 'C2', 'CL2', 'voice call sent', 105), 
 (6, '2024-02-01 11:20:00', 'U2', 'C2', 'CL2', 'message received', 106),
 (7, '2024-02-01 12:00:00', 'U3', 'C3', 'CL1', 'video call sent', 107),
 (8, '2024-02-01 12:15:00', 'U3', 'C3', 'CL1', 'voice call received', 108),
 (9, '2024-02-01 12:30:00', 'U3', 'C3', 'CL1', 'voice call sent', 109),
 (10, '2024-02-01 12:45:00', 'U3', 'C3', 'CL1', 'video call received', 110);
 
 with base as (select client_id as customer_inlist, count(*) as count_inlist from fact_event where
 event_type in ('video call received', 'video call sent','voice call received', 'voice call sent')
 group by client_id),
 base2 as (select f.client_id as client_id, count_inlist,count(f.event_type) from fact_event f join base b on customer_inlist=f.client_id
 group by f.client_id
 having count_inlist>=count(f.event_type)/2
 order by count_inlist desc)
 select client_id from base2 limit 1

/*.6....Write a query to find the Market Share at the Product Brand level for each Territory,
for Time Period Q4-2021. Market Share is the number of Products of a certain Product Brand 
brand sold in a territory, divided by the total number of Products sold in this Territory.
Output the ID of the Territory, name of the Product Brand and the corresponding Market 
Share in percentages. Only include these Product Brands that had at least one sale in a given territory.*/

drop table if exists fct_customer_sales;
CREATE TABLE fct_customer_sales (cust_id VARCHAR(50), prod_sku_id VARCHAR(50), order_date DATETIME,
 order_value BIGINT, order_id VARCHAR(50));
 
drop table if exists map_customer_territory;
CREATE TABLE map_customer_territory (cust_id VARCHAR(50), territory_id VARCHAR(50));

drop table if exists dim_product;
CREATE TABLE dim_product (prod_sku_id VARCHAR(50), prod_sku_name VARCHAR(255), prod_brand VARCHAR(100),
 market_name VARCHAR(100));

INSERT INTO fct_customer_sales (cust_id, prod_sku_id, order_date, order_value, order_id) VALUES 
('C001', 'P001', '2021-10-15', 100, 'O1001'), ('C002', 'P002', '2021-11-20', 200, 'O1002'),
 ('C003', 'P003', '2021-12-05', 150, 'O1003'), ('C001', 'P002', '2021-12-10', 300, 'O1004'),
 ('C002', 'P001', '2021-11-18', 250, 'O1005');

INSERT INTO map_customer_territory (cust_id, territory_id) VALUES ('C001', 'T001'),
 ('C002', 'T002'), ('C003', 'T001');
 
 INSERT INTO dim_product (prod_sku_id, prod_sku_name, prod_brand, market_name) VALUES 
 ('P001', 'Product A', 'Brand X', 'Market 1'), ('P002', 'Product B', 'Brand Y', 'Market 2'),
 ('P003', 'Product C', 'Brand X', 'Market 1');
 
 with base as (select quarter(f.order_date) quartername,year(f.order_date) yearname ,count(d.prod_sku_id) as sales,
 d.prod_brand, m.territory_id from map_customer_territory m join fct_customer_sales f 
 on m.cust_id=f.cust_id join dim_product d on d.prod_sku_id=f.prod_sku_id
 group by  d.prod_brand, m.territory_id,quarter(f.order_date),year(f.order_date) ),
  base2 as (select  territory_id, sum(sales)as total from base where quartername=4 and yearname=2021
 group by  territory_id)
 select  b.territory_id,b.prod_brand,
round((sum(sales)/total)*100,2) as share from base b join base2 b2 on b.territory_id=b2.territory_id
where quartername=4 and yearname=2021
 group by  b.territory_id, b.prod_brand
 order by b.territory_id,b.prod_brand;
 
 /* note for share of brand per territory is taken for the number of quanity of 
 brand sold/ brand sold by entire territory is taken */
 
 /* another way */
 with base3 as (select quarter(f.order_date) quartername,year(f.order_date) yearname ,count(d.prod_sku_id) as sales,
 d.prod_brand, m.territory_id from map_customer_territory m join fct_customer_sales f 
 on m.cust_id=f.cust_id join dim_product d on d.prod_sku_id=f.prod_sku_id
 group by  d.prod_brand, m.territory_id,quarter(f.order_date),year(f.order_date) )
 select prod_brand, territory_id, round( sum(sales)/((sum(sales) over(partition by territory_id)))*100,2) as share
 from base3 
 group by  prod_brand, territory_id,quartername,yearname
 
 /*7...... You have been asked to investigate whether there is a correlation between the average 
total order value and the average time in minutes between placing an order and having it 
delivered per restaurant.You have also been told that the column order_total represents 
the gross order total for each order. Therefore, you'll need to calculate the net order total.

The gross order total is the total of the order before adding the tip and deducting the 
discount and refund. Make sure correlation is rounded to 2 decimals */

drop table if exists delivery_details;
CREATE TABLE delivery_details (customer_placed_order_datetime   DATETIME, 
placed_order_with_restaurant_datetime DATETIME, driver_at_restaurant_datetime DATETIME,
 delivered_to_consumer_datetime   DATETIME, driver_id BIGINT, restaurant_id BIGINT, 
 consumer_id BIGINT, is_new TINYINT, delivery_region VARCHAR(255), is_asap TINYINT,
 order_total FLOAT, discount_amount FLOAT, tip_amount FLOAT, refunded_amount FLOAT);
 
 INSERT INTO delivery_details (customer_placed_order_datetime, placed_order_with_restaurant_datetime, 
 driver_at_restaurant_datetime, delivered_to_consumer_datetime, driver_id, restaurant_id, consumer_id,
 is_new, delivery_region, is_asap, order_total, discount_amount, tip_amount, refunded_amount) VALUES
('2024-02-01 12:00:00', '2024-02-01 12:05:00', '2024-02-01 12:15:00', '2024-02-01 12:30:00',
 101, 1, 1001, 1, 'New York', 1, 50.00, 5.00, 3.00, 0.00),
('2024-02-01 13:10:00', '2024-02-01 13:15:00', '2024-02-01 13:25:00', '2024-02-01 13:50:00',
 102, 2, 1002, 0, 'Los Angeles', 0, 75.00, 10.00, 5.00, 2.00),
('2024-02-01 14:30:00', '2024-02-01 14:40:00', '2024-02-01 14:50:00', '2024-02-01 15:05:00',
 103, 1, 1003, 1, 'New York', 1, 60.00, 8.00, 4.00, 0.00),
('2024-02-01 15:00:00', '2024-02-01 15:05:00', '2024-02-01 15:15:00', '2024-02-01 15:45:00',
 104, 3, 1004, 0, 'Chicago', 0, 90.00, 15.00, 6.00, 5.00),
('2024-02-01 16:20:00', '2024-02-01 16:25:00', '2024-02-01 16:35:00', '2024-02-01 16:50:00',
 105, 2, 1005, 1, 'Los Angeles', 1, 110.00, 20.00, 8.00, 0.00);
 
 select * from delivery_details;
 DESC delivery_details;
 
  /* formula r=((nΣxy)−(Σx)(Σy))/sqrt((n(Σx)^2-Σx^2)*(n(Σy)^2-Σy^2))*/

with base as (select restaurant_id, avg(timestampdiff(minute,
 customer_placed_order_datetime,delivered_to_consumer_datetime)) as difftime,
 avg(order_total-discount_amount- refunded_amount) as total from delivery_details
group by  restaurant_id),
 base2 as (select count(*) as f, sum(difftime) as Xsum, sum(total) as Ysum, sum(difftime*total) as XYsum,
		sum(pow(difftime,2)) as Xsqsum, sum(pow(total,2)) as Ysqsum from base),
        base3 as (select count(*) as f from delivery_details)
select (f*XYsum-(Xsum*Ysum))/sqrt(((f*Xsqsum)-pow(Xsum,2))*((f*Ysqsum)-pow(Ysum,2))) as
corr from base2 

/*8.... Given the users' sessions logs on a particular day, 
calculate how many hours each user was active that day.
Note: The session starts when state=1 and ends when state=0.*/
CREATE TABLE cust_tracking (cust_id VARCHAR(50), state BIGINT, timestamp DATETIME);

INSERT INTO cust_tracking (cust_id, state, timestamp) VALUES ('101', 1, '2024-01-10 08:00:00'), 
('101', 0, '2024-01-10 10:30:00'), ('101', 1, '2024-01-10 14:00:00'), ('101', 0, '2024-01-10 15:45:00'),
 ('102', 1, '2024-01-10 09:15:00'), ('102', 0, '2024-01-10 12:00:00'), ('103', 1, '2024-01-10 07:00:00'),
 ('103', 0, '2024-01-10 09:30:00'), ('103', 1, '2024-01-10 13:00:00'), ('103', 0, '2024-01-10 16:00:00');
 with base as (select cust_id, state, timestamp as currenttime, row_number()over(partition by cust_id order by timestamp),
 lead(timestamp)over(partition by cust_id order by timestamp) as endtime
 from cust_tracking )
 select cust_id,round(sum(timestampdiff(second, currenttime,endtime))/3600,2) as time_spend from base  where 
 endtime is not null and state =1
 group by cust_id 

/*9.... Find the number of employees who received the bonus and who didn't. Bonus values in employee table
 are corrupted so you should use values from the bonus table. Be aware of the fact that employee 
 can receive more than one bonus. Output value inside has_bonus column (1 if they had bonus, 0 if not)
 along with the corresponding number of employees for each.*/
 CREATE TABLE employee_details (id BIGINT PRIMARY KEY, first_name VARCHAR(50), last_name VARCHAR(50),
 age BIGINT, sex VARCHAR(10), email VARCHAR(100), address VARCHAR(100), city VARCHAR(50), 
 department VARCHAR(50), employee_title VARCHAR(50), manager_id BIGINT, salary BIGINT, target BIGINT,
 bonus BIGINT);

INSERT INTO employee_details (id, first_name, last_name, age, sex, email, address, city, department, 
employee_title, manager_id, salary, target, bonus)VALUES 
(1, 'John', 'Doe', 30, 'Male', 'john.doe@example.com', '123 Elm St', 'New York', 'IT', 'Engineer', 
101, 70000, 80000, 5000),(2, 'Jane', 'Smith', 28, 'Female', 'jane.smith@example.com', '456 Oak St', 
'Los Angeles', 'HR', 'Manager', 102, 75000, 90000, NULL),(3, 'Alice', 'Johnson', 35, 'Female', 
'alice.johnson@example.com', '789 Pine St', 'Chicago', 'Finance', 'Analyst', 103, 80000, 95000, NULL),
(4, 'Bob', 'Brown', 40, 'Male', 'bob.brown@example.com', '321 Maple St', 'Boston', 'IT', 'Director',
 104, 120000, 130000, NULL),(5, 'Charlie', 'Davis', 25, 'Male', 'charlie.davis@example.com', 
 '654 Cedar St', 'Seattle', 'Marketing', 'Specialist', 105, 50000, 60000, NULL);
 
 CREATE TABLE bonus (worker_ref_id BIGINT, bonus_amount BIGINT, bonus_date DATETIME);

INSERT INTO bonus (worker_ref_id, bonus_amount, bonus_date) VALUES (1, 5000, '2024-01-15'),
(1, 3000, '2024-02-20'),(3, 2000, '2024-03-10'),(5, 1000, '2024-04-05');

with base as (select id ,
case when id in (select worker_ref_id from  bonus) then 1
else 0
end as status
from employee_details)
select status,count(id) as employee_count from base group by status;

/* 11....Write a query to calculate the distribution of comments by the count of users that joined 
Meta/Facebook between 2018 and 2020, for the month of January 2020.

The output should contain a count of comments and the corresponding number of users that made 
that number of comments in Jan-2020. For example, you'll be counting how many users made 1 comment,
 2 comments, 3 comments, 4 comments, etc in Jan-2020. Your left column in the output will be the 
 number of comments while your right column in the output will be the number of users. 
 Sort the output from the least number of comments to highest.*/
 drop table if exists fb_users;
 CREATE TABLE fb_users (city_id BIGINT, device BIGINT, id BIGINT PRIMARY KEY, joined_at DATETIME,
 name VARCHAR(255));
 INSERT INTO fb_users (city_id, device, id, joined_at, name) VALUES(101, 1, 1, '2019-06-15', 'Alice'),
 (102, 2, 2, '2020-03-10', 'Bob'),(103, 1, 3, '2018-11-25', 'Charlie'),(104, 3, 4, '2017-09-05', 'David'),
 (105, 1, 5, '2019-01-20', 'Eve'),(106, 2, 6, '2020-01-05', 'Frank');
 
 CREATE TABLE fb_comments (body VARCHAR(255),created_at DATETIME,user_id BIGINT,FOREIGN KEY (user_id)
 REFERENCES fb_users(id));

INSERT INTO fb_comments (body, created_at, user_id) VALUES ('Great post!', '2020-01-01 10:00:00', 1),
 ('Interesting article', '2020-01-02 12:30:00', 1), ('Thanks for sharing!', '2020-01-05 08:20:00', 2),
 ('Nice update', '2020-01-08 15:45:00', 3), ('Good job', '2020-01-12 14:00:00', 3), 
 ('Helpful content', '2020-01-14 09:00:00', 3), ('Loved it!', '2020-01-18 11:10:00', 5), 
 ('Noted', '2020-01-20 17:40:00', 6), ('Cool!', '2020-01-22 08:55:00', 6), 
 ('Agreed', '2020-01-25 19:30:00', 6), ('Well written', '2020-01-28 20:45:00', 1),
 ('Informative', '2020-01-30 13:50:00', 5), ('Awesome', '2019-12-31 23:59:00', 2);
 with base as(select id from fb_users
 where year(joined_at) between 2018 and 2020),
base2 as(
 select fb.user_id,fb.body, fb.created_at  from fb_comments fb join base b on fb.user_id=b.id where
 fb.created_at >='2020-01-01' and fb.created_at<'2020-02-01' ),
 base3 as (select user_id,count(body) message_count from base2
 group by user_id )
 select count(u.id) as 'count(id)',c.message_count from base3 c left join base u on c.user_id=u.id
 group by c.message_count 
 order by c.message_count; 

/*12... Find the average absolute fare difference between a specific passenger and all passengers that
 belong to the same pclass, both are non-survivors and age difference between two of them is 5 or
 less years. Do that for each passenger (that satisfy above mentioned coniditions).
 Output the result along with the passenger name.*/
 
 CREATE TABLE titanic ( passengerid BIGINT PRIMARY KEY, name VARCHAR(255), pclass BIGINT, survived BIGINT,
 age FLOAT, fare FLOAT, cabin VARCHAR(50), embarked VARCHAR(1), parch BIGINT, sibsp BIGINT, 
 ticket VARCHAR(50), sex VARCHAR(10));

INSERT INTO titanic (passengerid, name, pclass, survived, age, fare, cabin, embarked, parch, 
sibsp, ticket, sex) VALUES (1, 'John Smith', 1, 0, 35, 71.28, 'C85', 'C', 0, 1, 'PC 17599', 'male'),
 (2, 'Mary Johnson', 1, 0, 30, 53.1, 'C123', 'C', 0, 0, 'PC 17601', 'female'), 
 (3, 'James Brown', 1, 1, 40, 50.0, NULL, 'S', 0, 0, '113803', 'male'), 
 (4, 'Anna Davis', 2, 0, 28, 13.5, NULL, 'S', 0, 1, '250644', 'female'),
 (5, 'Robert Wilson', 2, 0, 32, 13.5, NULL, 'S', 0, 1, '250655', 'male'), 
 (6, 'Emma Moore', 3, 0, 25, 7.25, NULL, 'S', 0, 0, '349909', 'female'), 
 (7, 'William Taylor', 3, 0, 27, 7.75, NULL, 'Q', 0, 0, 'STON/O 2. 3101282', 'male'),
 (8, 'Sophia Anderson', 3, 1, 22, 8.05, NULL, 'S', 0, 0, '347082', 'female'), 
 (9, 'David Thomas', 1, 0, 36, 71.28, 'C85', 'C', 0, 1, 'PC 17599', 'male'),
 (10, 'Alice Walker', 1, 0, 33, 53.1, 'C123', 'C', 0, 0, 'PC 17601', 'female');
 
 with base as (select t2.name,(abs(t2.fare-t1.fare)) as avgabsfare  from titanic t1  join titanic t2 on
 t1.passengerid!=t2.passengerid and abs(t2.age-t1.age)<=5 and t2.survived=0 and
 t1.survived=0 and t1.pclass=t2.pclass and t1.fare is not null )
 select name, avg(avgabsfare) from base group by name;

/* 13.... Calculate the total number of interactions and the total number of contents created for each customer.
 Include all interaction types and content types in your calculations. Your output should include 
 the customer's ID, the total number of interactions, and the total number of content items.*/
 
 CREATE TABLE customer_interactions (customer_id BIGINT, interaction_date DATETIME, 
 interaction_id BIGINT, interaction_type VARCHAR(50));

INSERT INTO customer_interactions (customer_id, interaction_date, interaction_id, interaction_type) 
VALUES (1, '2023-01-15 10:30:00', 101, 'Click'), (1, '2023-01-16 11:00:00', 102, 'Purchase'),
 (2, '2023-01-17 14:45:00', 103, 'View'), (3, '2023-01-18 09:20:00', 104, 'Share'), 
 (3, '2023-01-18 09:25:00', 105, 'Like'), (4, '2023-01-19 12:10:00', 106, 'Comment');
 
 CREATE TABLE user_contents (content_id BIGINT, content_text VARCHAR(255), content_type VARCHAR(50),
 customer_id BIGINT);

INSERT INTO user_contents (content_id, content_text, content_type, customer_id) VALUES 
(201, 'Welcome Post', 'Blog', 1), (202, 'Product Review', 'Review', 2), 
(203, 'Event Photos', 'Photo', 3), (204, 'Tutorial Video', 'Video', 3), 
(205, 'Survey Response', 'Survey', 4);
with base as (select distinct customer_id,count(interaction_type) as interaction_type from customer_interactions 
group by customer_id)
 select c.customer_id,interaction_type as total_interaction,
 count(coalesce(u.content_type,0)) as total_content from base c left join 
 user_contents u on c.customer_id = u.customer_id group by
 c.customer_id;


/*.14.... Find the number of words in each business name. Avoid counting special symbols as words (e.g. &). 
Output the business name and its count of words.*/

CREATE TABLE sf_restaurant_health_violations ( business_address VARCHAR(255), business_city VARCHAR(100), 
business_id BIGINT, business_latitude FLOAT, business_location VARCHAR(255), business_longitude FLOAT,
 business_name VARCHAR(255), business_phone_number BIGINT, business_postal_code VARCHAR(20),
 business_state VARCHAR(50), inspection_date DATETIME, inspection_id VARCHAR(100),
 inspection_score FLOAT, inspection_type VARCHAR(100), risk_category VARCHAR(100),
 violation_description VARCHAR(255), violation_id VARCHAR(100));

INSERT INTO sf_restaurant_health_violations ( business_address, business_city, business_id, 
business_latitude, business_location, business_longitude, business_name, business_phone_number, business_postal_code, business_state, inspection_date, inspection_id, inspection_score, inspection_type, risk_category, violation_description, violation_id) VALUES 
('123 Main St', 'San Francisco', 101, 37.7749, '123 Main St, San Francisco, CA', 
-122.4194, 'John''s Pizza & Grill', 4151234567, '94103', 'CA', '2024-12-20', 'I101', 85.5,
 'Routine Inspection', 'Low Risk', 'Cleanliness issue', 'V101'),
('456 Market St', 'San Francisco', 102, 37.7741, '456 Market St, San Francisco, CA', -122.4202, 
'Sushi-Hub', 4159876543, '94104', 'CA', '2024-12-15', 'I102', 90.0, 'Routine Inspection', 
'Moderate Risk', 'Improper food storage', 'V102'),
('789 Mission St', 'San Francisco', 103, 37.7753, '789 Mission St, San Francisco, CA', -122.4175, 
'The Good Eatery Cafe', 4155551212, '94105', 'CA', '2024-12-10', 'I103', 88.5, 'Follow-Up Inspection', 
'High Risk', 'Cross-contamination issue', 'V103'),('321 Broadway', 'San Francisco', 104, 37.7764, 
'321 Broadway, San Francisco, CA', -122.4188, 'Burger Palace & More', 4152223333, '94106', 'CA', 
'2024-12-05', 'I104', 80.0, 'Routine Inspection', 'Low Risk', 'Expired food', 'V104'),
('654 Polk St', 'San Francisco', 105, 37.7775, '654 Polk St, San Francisco, CA', -122.4167,
 'Quick_&_Fresh', 4154445555, '94107', 'CA', '2024-12-01', 'I105', 75.0, 'Routine Inspection', 
 'Moderate Risk', 'Improper sanitation', 'V105');
 
 with base as (select business_name,
 length(regexp_replace(business_name,"[^a-zA-Z  &]",''))-
 length(replace(trim(regexp_replace(business_name,"[^a-zA-Z &]",''))," ","")) +1 as counts
 from
 sf_restaurant_health_violations)
 select business_name,
 case  when business_name like '%\_&\_%' then counts
 when business_name like '%&%'  then counts-1
 else counts
 end as counts from base;

/*14.... You are given a table of tennis players and their matches that they could either win
 (W) or lose (L). Find the longest streak of wins. A streak is a set of 
 consecutive won matches of one player. The streak ends once a player loses their next match. 
 Output the ID of the player or players and the length of the streak.*/
 
 CREATE TABLE players_results ( match_date DATETIME, match_result VARCHAR(1), player_id BIGINT);

INSERT INTO players_results (match_date, match_result, player_id) VALUES ('2023-01-01', 'W', 1),
 ('2023-01-02', 'W', 1), ('2023-01-03', 'L', 1), ('2023-01-04', 'W', 1), ('2023-01-01', 'L', 2), 
 ('2023-01-02', 'W', 2), ('2023-01-03', 'W', 2), ('2023-01-04', 'W', 2), ('2023-01-05', 'L', 2), 
 ('2023-01-01', 'W', 3), ('2023-01-02', 'W', 3), ('2023-01-03', 'W', 3), ('2023-01-04', 'W', 3),
 ('2023-01-05', 'L', 3);
 
 with base as (select *,
 row_number()over(partition by player_id order by match_date) as streak from players_results
 where match_result='W'),
 base2 as( select *, (date(match_date)- interval streak  day ) as new_dates from base)
 select player_id ,count(*) as winning_streak from base2 group by new_dates, player_id
 order by (count(*)) 
desc limit 1;

/*15....We want to identify the most suspicious claims in each state. We'll consider the top 5 percentile 
of claims with the highest fraud scores in each state as potentially fraudulent.*/

CREATE TABLE claims (policy_number VARCHAR(50), state VARCHAR(50), claim_cost FLOAT, fraud_score FLOAT);

INSERT INTO claims (policy_number, state, claim_cost, fraud_score) VALUES ('POL123', 'CA', 10000.00, 85.5),
 ('POL124', 'CA', 5000.00, 70.2), ('POL125', 'CA', 20000.00, 92.8), ('POL126', 'NY', 15000.00, 88.1), 
 ('POL127', 'NY', 8000.00, 65.4), ('POL128', 'NY', 25000.00, 93.7), ('POL129', 'TX', 12000.00, 75.3), 
 ('POL130', 'TX', 18000.00, 95.2), ('POL131', 'TX', 9000.00, 60.0), ('POL132', 'FL', 11000.00, 82.0), 
 ('POL133', 'FL', 14000.00, 87.5), ('POL134', 'FL', 30000.00, 99.0);
 
 with base as (select *,row_number()over( partition by state order by fraud_score) as
 prec, count(*)over( partition by state) as pos from claims),
 base2 as(select state, fraud_score as mark from base where prec=ceil(0.95*pos))
 select b1.policy_number,b1.state, b1.claim_cost,b1.fraud_score,b2.mark from base b1 join base2 b2 on 
 b1.state= b2.state WHERE b1.fraud_score >= b2.mark;
