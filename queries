Use  maven_advanced_sql;
show tables;
/1...* A group of travelers embark on world tours starting with their home cities. Each traveler 
has an undecided itinerary that evolves over the course of the tour. Some travelers decide to 
abruptly end their journey mid-travel and live in their last destination.
Given the dataset of dates on which they travelled between different pairs of cities, 
can you find out how many travellers ended back in their home city? For simplicity, 
you can assume that each traveler made at most one trip between two cities in a day.*/

describe employee_salary_data;
CREATE TABLE travel_history (date DATE, start_city VARCHAR(50), end_city VARCHAR(50), traveler VARCHAR(50));

INSERT INTO travel_history (date, start_city, end_city, traveler) VALUES ('2024-01-01', 'Delhi', 'Dubai', 'Amit'),
 ('2024-01-05', 'Dubai', 'London', 'Amit'), ('2024-01-10', 'London', 'Delhi', 'Amit'), 
 ('2024-02-01', 'Mumbai', 'Singapore', 'Priya'), ('2024-02-05', 'Singapore', 'Sydney', 'Priya'), 
 ('2024-02-10', 'Sydney', 'New York', 'Priya'), ('2024-03-01', 'Kolkata', 'Bangkok', 'Raj'), 
 ('2024-03-03', 'Bangkok', 'Tokyo', 'Raj'), ('2024-03-07', 'Tokyo', 'Kolkata', 'Raj'), 
 ('2024-04-01', 'Bangalore', 'Paris', 'Neha'), ('2024-04-05', 'Paris', 'Rome', 'Neha'),
 ('2024-04-10', 'Rome', 'Berlin', 'Neha'), ('2024-05-01', 'Chennai', 'Dubai', 'Arjun'), 
 ('2024-05-03', 'Dubai', 'Amsterdam', 'Arjun'), ('2024-05-06', 'Amsterdam', 'Chennai', 'Arjun'); 
 
 with base as (select *,row_number()over(partition by traveler order by date) ranks from travel_history),
 base2 as(select traveler, end_city as endcity from base where ranks=(select max(ranks) from base)
 group by traveler, end_city),
 base3 as (select traveler, start_city as startcity from base where ranks=(select min(ranks) from base)
 group by traveler, start_city)
 select b2.traveler, b3.startcity, b2.endcity from base2 b2 join base3 b3 on b2.traveler=b3.traveler
 where b3.startcity=b2.endcity;



/*2... Each Employee is assigned one territory and is responsible for the Customers from this territory. 
There may be multiple employees assigned to the same territory.
Write a query to get the Employees who are responsible for the maximum number of Customers.
 Output the Employee ID and the number of Customers*/

CREATE TABLE map_employee_territory (empl_id VARCHAR(10), territory_id VARCHAR(10));

INSERT INTO map_employee_territory (empl_id, territory_id) VALUES ('E849', 'T3'), 
('E850', 'T3'), ('E851', 'T3'), ('E852', 'T1'), ('E853', 'T2'), ('E854', 'T5'), 
('E855', 'T5'), ('E856', 'T4'), ('E857', 'T2');

CREATE TABLE map_customer_territory (cust_id VARCHAR(10), territory_id VARCHAR(10));

INSERT INTO map_customer_territory (cust_id, territory_id) VALUES ('C273', 'T3'), 
('C274', 'T3'), ('C275', 'T1'), ('C276', 'T1'), ('C277', 'T1'), ('C278', 'T2'), 
('C279', 'T2'), ('C280', 'T4'), ('C281', 'T4'), ('C282', 'T4'), ('C283', 'T4'), 
('C284', 'T5'), ('C285', 'T5'), ('C286', 'T3'), ('C287', 'T3');

with base as (select e.empl_id,e.territory_id,cust_id from map_employee_territory e join map_customer_territory c
on e.territory_id=c.territory_id),
base2 as (select empl_id,(count(cust_id)) as count from base group by empl_id)
select empl_id,count from base2 where count=( select max(count) from base2);


/*3... Write a query to return Territory and corresponding Sales Growth.
 Compare growth between periods Q4-2021 vs Q3-2021.
 If Territory (say T123) has Sales worth $100 in Q3-2021 and Sales worth $110 in Q4-2021,
 then the Sales Growth will be 10% [ i.e. = ((110 - 100)/100) * 100 ]*/
 
 CREATE TABLE fct_customer_sale (cust_id VARCHAR(50), 
 prod_sku_id VARCHAR(50), order_date DATETIME, 
 order_value BIGINT, order_id VARCHAR(50));

CREATE TABLE map_customer_territories (cust_id VARCHAR(50),
 territory_id VARCHAR(50));

INSERT INTO fct_customer_sale (cust_id, prod_sku_id, order_date, 
order_value, order_id) VALUES ('C001', 'P100', '2021-07-15', 100, 'O1001'),
 ('C002', 'P101', '2021-07-20', 200, 'O1002'),
 ('C001', 'P100', '2021-10-05', 150, 'O1003'), 
 ('C002', 'P101', '2021-10-10', 250, 'O1004'), 
 ('C003', 'P102', '2021-08-22', 180, 'O1005'), 
 ('C003', 'P102', '2021-11-30', 210, 'O1006');
 

INSERT INTO map_customer_territories (cust_id, territory_id) VALUES  ('C001', 'T001'),
 ('C002', 'T002'), ('C003', 'T003');
 /* one way to write it*/
with base as (select c.cust_id, c.prod_sku_id, monthname(c.order_date) as namemonth,
year(c.order_date) as nameyear,  quarter(c.order_date) AS quartername,
c.order_value, c.order_id ,t.territory_id from
fct_customer_sale c join map_customer_territories t on c.cust_id=t.cust_id),
base2 as (select territory_id,sum(order_value)as revenue,quartername,nameyear from 
base group by territory_id,nameyear,quartername),
base3 as (select territory_id,revenue,nameyear,quartername,
row_number()over(partition by territory_id order by revenue ) as ranks,
lead(revenue)over(partition by territory_id
 order by revenue ) as next
 from base2)
 select territory_id, concat(((next-revenue)/revenue)*100,'%') as sales_growth_perc 
 from base3 where next is not null;
 
 /* other way */
 with base as (select t.territory_id,  year(c.order_date) as nameyear,
 quarter(c.order_date) AS quartername,sum(c.order_value)as revenue from
fct_customer_sale c join map_customer_territories t on c.cust_id=t.cust_id
group by t.territory_id, year(c.order_date),
 quarter(c.order_date))
 select q3.territory_id, concat(((q4.revenue-q3.revenue)/q3.revenue)*100,'%') as sales_growth_perc 
 from base q3 join base q4 on q3.territory_id=q4.territory_id
 where q3.nameyear=q4.nameyear and q3.quartername=3 and q4.quartername=4
 where next is not null;

/*4... From users who had their first session as a viewer, how many streamer 
sessions have they had? Return the user id and number of sessions in descending order.
 In case there are users with the same number of sessions, order them by ascending user id.*/
 
 CREATE TABLE twitch_sessions (user_id BIGINT, session_start DATETIME, session_end DATETIME, 
 session_id BIGINT PRIMARY KEY, session_type VARCHAR(20) CHECK (session_type IN ('viewer', 'streamer')));

INSERT INTO twitch_sessions (user_id, session_start, session_end, session_id, session_type) 
VALUES (101, '2024-02-01 10:00:00', '2024-02-01 11:00:00', 1, 'viewer'), 
(101, '2024-02-02 14:00:00', '2024-02-02 15:30:00', 2, 'streamer'), 
(102, '2024-02-01 09:30:00', '2024-02-01 10:30:00', 3, 'viewer'), 
(102, '2024-02-03 16:00:00', '2024-02-03 17:00:00', 4, 'streamer'),
 (102, '2024-02-05 18:00:00', '2024-02-05 19:30:00', 5, 'streamer'), 
 (103, '2024-02-02 11:00:00', '2024-02-02 12:00:00', 6, 'viewer'), 
 (104, '2024-02-01 08:30:00', '2024-02-01 09:00:00', 7, 'viewer'), 
 (104, '2024-02-04 20:00:00', '2024-02-04 21:00:00', 8, 'streamer'),
 (104, '2024-02-06 22:00:00', '2024-02-06 23:00:00', 9, 'streamer'),
 (104, '2024-02-07 15:00:00', '2024-02-07 16:30:00', 10, 'streamer');
 /* this query gives user id which have session as viwer and streamer*/
 select  user_id,count(session_type='streamer')  from twitch_sessions t1 where t1.user_id in
 (select user_id  from twitch_sessions t2 where 
session_type ='viewer')
group by user_id;
 /* we require user_id with first session as viewer and also had streamer session*/
 with base as (select user_id, session_type,row_number()over(partition by user_id order by
 session_start) as ranks  from twitch_sessions t2),
base2 as (select  user_id  from base where ranks=1 and session_type='viewer')
select t1.user_id, count(*) from twitch_sessions t1 join base2 b on b.user_id=t1.user_id
where t1.session_type='streamer'
group by user_id order by count(*) desc;

/* other way*/
 select  user_id,count(session_type='streamer')  from twitch_sessions t1 where t1.user_id in
 (select user_id  from twitch_sessions t2 where 
session_type ='viewer')
group by user_id;
 /* we require user_id with first session as viewer and also had streamer session*/
 with base as (select user_id, min(session_start) from twitch_sessions t2 
 where session_type='viewer'
 group by user_id )
select t1.user_id, count(*) from twitch_sessions t1 join base b on b.user_id=t1.user_id
where t1.session_type='streamer'
group by user_id order by count(*) desc;


/*5... Select the most popular client_id based on a count of the number of users who have at 
least 50% of their events from the following list: 'video call received', 'video call sent',
 'voice call received', 'voice call sent'.*/
 
 CREATE TABLE fact_event (id BIGINT PRIMARY KEY, time_id DATETIME, user_id VARCHAR(50),
 customer_id VARCHAR(50), client_id VARCHAR(50), event_type VARCHAR(50), event_id BIGINT);
 
 INSERT INTO fact_event (id, time_id, user_id, customer_id, client_id, event_type, event_id)
 VALUES (1, '2024-02-01 10:00:00', 'U1', 'C1', 'CL1', 'video call received', 101),
 (2, '2024-02-01 10:05:00', 'U1', 'C1', 'CL1', 'video call sent', 102),
 (3, '2024-02-01 10:10:00', 'U1', 'C1', 'CL1', 'message sent', 103),
 (4, '2024-02-01 11:00:00', 'U2', 'C2', 'CL2', 'voice call received', 104),
 (5, '2024-02-01 11:10:00', 'U2', 'C2', 'CL2', 'voice call sent', 105), 
 (6, '2024-02-01 11:20:00', 'U2', 'C2', 'CL2', 'message received', 106),
 (7, '2024-02-01 12:00:00', 'U3', 'C3', 'CL1', 'video call sent', 107),
 (8, '2024-02-01 12:15:00', 'U3', 'C3', 'CL1', 'voice call received', 108),
 (9, '2024-02-01 12:30:00', 'U3', 'C3', 'CL1', 'voice call sent', 109),
 (10, '2024-02-01 12:45:00', 'U3', 'C3', 'CL1', 'video call received', 110);
 
 with base as (select client_id as customer_inlist, count(*) as count_inlist from fact_event where
 event_type in ('video call received', 'video call sent','voice call received', 'voice call sent')
 group by client_id),
 base2 as (select f.client_id as client_id, count_inlist,count(f.event_type) from fact_event f join base b on customer_inlist=f.client_id
 group by f.client_id
 having count_inlist>=count(f.event_type)/2
 order by count_inlist desc)
 select client_id from base2 limit 1

/*.6....Write a query to find the Market Share at the Product Brand level for each Territory,
for Time Period Q4-2021. Market Share is the number of Products of a certain Product Brand 
brand sold in a territory, divided by the total number of Products sold in this Territory.
Output the ID of the Territory, name of the Product Brand and the corresponding Market 
Share in percentages. Only include these Product Brands that had at least one sale in a given territory.*/

drop table if exists fct_customer_sales;
CREATE TABLE fct_customer_sales (cust_id VARCHAR(50), prod_sku_id VARCHAR(50), order_date DATETIME,
 order_value BIGINT, order_id VARCHAR(50));
 
drop table if exists map_customer_territory;
CREATE TABLE map_customer_territory (cust_id VARCHAR(50), territory_id VARCHAR(50));

drop table if exists dim_product;
CREATE TABLE dim_product (prod_sku_id VARCHAR(50), prod_sku_name VARCHAR(255), prod_brand VARCHAR(100),
 market_name VARCHAR(100));

INSERT INTO fct_customer_sales (cust_id, prod_sku_id, order_date, order_value, order_id) VALUES 
('C001', 'P001', '2021-10-15', 100, 'O1001'), ('C002', 'P002', '2021-11-20', 200, 'O1002'),
 ('C003', 'P003', '2021-12-05', 150, 'O1003'), ('C001', 'P002', '2021-12-10', 300, 'O1004'),
 ('C002', 'P001', '2021-11-18', 250, 'O1005');

INSERT INTO map_customer_territory (cust_id, territory_id) VALUES ('C001', 'T001'),
 ('C002', 'T002'), ('C003', 'T001');
 
 INSERT INTO dim_product (prod_sku_id, prod_sku_name, prod_brand, market_name) VALUES 
 ('P001', 'Product A', 'Brand X', 'Market 1'), ('P002', 'Product B', 'Brand Y', 'Market 2'),
 ('P003', 'Product C', 'Brand X', 'Market 1');
 
 with base as (select quarter(f.order_date) quartername,year(f.order_date) yearname ,count(d.prod_sku_id) as sales,
 d.prod_brand, m.territory_id from map_customer_territory m join fct_customer_sales f 
 on m.cust_id=f.cust_id join dim_product d on d.prod_sku_id=f.prod_sku_id
 group by  d.prod_brand, m.territory_id,quarter(f.order_date),year(f.order_date) ),
  base2 as (select  territory_id, sum(sales)as total from base where quartername=4 and yearname=2021
 group by  territory_id)
 select  b.territory_id,b.prod_brand,
round((sum(sales)/total)*100,2) as share from base b join base2 b2 on b.territory_id=b2.territory_id
where quartername=4 and yearname=2021
 group by  b.territory_id, b.prod_brand
 order by b.territory_id,b.prod_brand;
 
 /* note for share of brand per territory is taken for the number of quanity of 
 brand sold/ brand sold by entire territory is taken */
 
 /* another way */
 with base3 as (select quarter(f.order_date) quartername,year(f.order_date) yearname ,count(d.prod_sku_id) as sales,
 d.prod_brand, m.territory_id from map_customer_territory m join fct_customer_sales f 
 on m.cust_id=f.cust_id join dim_product d on d.prod_sku_id=f.prod_sku_id
 group by  d.prod_brand, m.territory_id,quarter(f.order_date),year(f.order_date) )
 select prod_brand, territory_id, round( sum(sales)/((sum(sales) over(partition by territory_id)))*100,2) as share
 from base3 
 group by  prod_brand, territory_id,quartername,yearname
 
 /*7...... You have been asked to investigate whether there is a correlation between the average 
total order value and the average time in minutes between placing an order and having it 
delivered per restaurant.You have also been told that the column order_total represents 
the gross order total for each order. Therefore, you'll need to calculate the net order total.

The gross order total is the total of the order before adding the tip and deducting the 
discount and refund. Make sure correlation is rounded to 2 decimals */

drop table if exists delivery_details;
CREATE TABLE delivery_details (customer_placed_order_datetime   DATETIME, 
placed_order_with_restaurant_datetime DATETIME, driver_at_restaurant_datetime DATETIME,
 delivered_to_consumer_datetime   DATETIME, driver_id BIGINT, restaurant_id BIGINT, 
 consumer_id BIGINT, is_new TINYINT, delivery_region VARCHAR(255), is_asap TINYINT,
 order_total FLOAT, discount_amount FLOAT, tip_amount FLOAT, refunded_amount FLOAT);
 
 INSERT INTO delivery_details (customer_placed_order_datetime, placed_order_with_restaurant_datetime, 
 driver_at_restaurant_datetime, delivered_to_consumer_datetime, driver_id, restaurant_id, consumer_id,
 is_new, delivery_region, is_asap, order_total, discount_amount, tip_amount, refunded_amount) VALUES
('2024-02-01 12:00:00', '2024-02-01 12:05:00', '2024-02-01 12:15:00', '2024-02-01 12:30:00',
 101, 1, 1001, 1, 'New York', 1, 50.00, 5.00, 3.00, 0.00),
('2024-02-01 13:10:00', '2024-02-01 13:15:00', '2024-02-01 13:25:00', '2024-02-01 13:50:00',
 102, 2, 1002, 0, 'Los Angeles', 0, 75.00, 10.00, 5.00, 2.00),
('2024-02-01 14:30:00', '2024-02-01 14:40:00', '2024-02-01 14:50:00', '2024-02-01 15:05:00',
 103, 1, 1003, 1, 'New York', 1, 60.00, 8.00, 4.00, 0.00),
('2024-02-01 15:00:00', '2024-02-01 15:05:00', '2024-02-01 15:15:00', '2024-02-01 15:45:00',
 104, 3, 1004, 0, 'Chicago', 0, 90.00, 15.00, 6.00, 5.00),
('2024-02-01 16:20:00', '2024-02-01 16:25:00', '2024-02-01 16:35:00', '2024-02-01 16:50:00',
 105, 2, 1005, 1, 'Los Angeles', 1, 110.00, 20.00, 8.00, 0.00);
 
 select * from delivery_details;
 DESC delivery_details;
 
  /* formula r=((nΣxy)−(Σx)(Σy))/sqrt((n(Σx)^2-Σx^2)*(n(Σy)^2-Σy^2))*/

with base as (select restaurant_id, avg(timestampdiff(minute,
 customer_placed_order_datetime,delivered_to_consumer_datetime)) as difftime,
 avg(order_total-discount_amount- refunded_amount) as total from delivery_details
group by  restaurant_id),
 base2 as (select count(*) as f, sum(difftime) as Xsum, sum(total) as Ysum, sum(difftime*total) as XYsum,
		sum(pow(difftime,2)) as Xsqsum, sum(pow(total,2)) as Ysqsum from base),
        base3 as (select count(*) as f from delivery_details)
select (f*XYsum-(Xsum*Ysum))/sqrt(((f*Xsqsum)-pow(Xsum,2))*((f*Ysqsum)-pow(Ysum,2))) as
corr from base2 

/*8.... Given the users' sessions logs on a particular day, 
calculate how many hours each user was active that day.
Note: The session starts when state=1 and ends when state=0.*/
CREATE TABLE cust_tracking (cust_id VARCHAR(50), state BIGINT, timestamp DATETIME);

INSERT INTO cust_tracking (cust_id, state, timestamp) VALUES ('101', 1, '2024-01-10 08:00:00'), 
('101', 0, '2024-01-10 10:30:00'), ('101', 1, '2024-01-10 14:00:00'), ('101', 0, '2024-01-10 15:45:00'),
 ('102', 1, '2024-01-10 09:15:00'), ('102', 0, '2024-01-10 12:00:00'), ('103', 1, '2024-01-10 07:00:00'),
 ('103', 0, '2024-01-10 09:30:00'), ('103', 1, '2024-01-10 13:00:00'), ('103', 0, '2024-01-10 16:00:00');
 with base as (select cust_id, state, timestamp as currenttime, row_number()over(partition by cust_id order by timestamp),
 lead(timestamp)over(partition by cust_id order by timestamp) as endtime
 from cust_tracking )
 select cust_id,round(sum(timestampdiff(second, currenttime,endtime))/3600,2) as time_spend from base  where 
 endtime is not null and state =1
 group by cust_id 
 
